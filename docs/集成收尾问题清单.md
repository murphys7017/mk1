# mk1 当前代码需要收尾的集成问题清单

本文档聚焦“能跑通主链路 + 各模块真实接线”的工程收尾问题，按优先级从高到低排列。

## P0（会直接导致主流程不可用 / 产出为空）

1. **输入协议不一致（main → Alice → PerceptionSystem）**
   - ✅ 已修复：当前 [main.py](../main.py) 已统一为 `{"text": user_input}`，与 `PerceptionSystem` 的 analyzer 映射一致。

2. **`Alice.respond()` 尚未把上下文组装器接入**
   - ✅ 已修复：[Alice.py](../Alice.py) 已在初始化时创建 `DefaultGlobalContextAssembler`，并在 `respond()` 中使用 `messages = self.assembler.build_messages()`。

3. **`ContextAssembler/DefaultGlobalContextAssembler` 依赖的方法当前不存在**
   - ✅ 已部分修复：
     - [ChatStateSystem/ChatStateSystem.py](../ChatStateSystem/ChatStateSystem.py) 已定义 `assemble()` 抽象接口，并提供 [ChatStateSystem/DefaultChatStateSystem.py](../ChatStateSystem/DefaultChatStateSystem.py) 默认实现。
     - `DefaultGlobalContextAssembler` 已改为依赖 `MemorySystem.assemble()` + `ChatStateSystem.assemble()`。
   - 仍需确认：`Alice` 实例化时是否真正创建了 `DefaultChatStateSystem` 并注入给 assembler（否则仍未接线）。

## P1（逻辑已写但会静默失效 / 质量显著下降）

1. **摘要生成 prompt 的字段命名仍不一致（summarize_dialogue）**
   - 现状：[SystemPrompt.py](../SystemPrompt.py) 中 `summarize_dialogue` 模板使用 `{summary_text}` / `{dialogues_text}`。
   - ✅ 已修复：`DialogueStorage.summarize_dialogue()` 已改为向 `LLMManagement.generate()` 传递 `summary_text` 和 `dialogues_text`（与 `SystemPrompt` 的 `required_fields` 对齐），摘要生成调用现在可正常命中模板。
   - 建议：后续新增 prompt 时仍需保持 `PromptTemplate.required_fields` 与调用处传参名一致，避免类似问题复现。

2. **LLMManagement 的模型映射与实现映射不一致（qwen-plus）**
   - 现状：[LLM/LLMManagement.py](../LLM/LLMManagement.py) 的 `model_map` 有 `generate_response: qwen-plus`，但 `llm_map` 没有 `qwen-plus` 这个 key。
   - 结果：一旦走 `generate_response` 路径会拿不到 llm 实现。
   - 建议：要么把 `llm_map` 增加 `"qwen-plus": QwenFormated()`，要么把 `model_map` 改为指向已有 key（并统一命名）。

3. **QwenFormated 强制 JSON 输出，不一定适用于“生成自然语言回复”**
   - 现状：[LLM/QwenFormated.py](../LLM/QwenFormated.py) 固定 `response_format={"type": "json_object"}`。
   - 风险：如果用于 chat 回复生成，模型会被迫输出 JSON，而不是自然语言。
   - 建议：把“结构化决策类 prompt”和“自然语言回复生成”分开：决策类保持 JSON；回复生成不要强制 JSON。

4. **数据模型混用（MessageModel vs DataClass）**
   - 现状：
     - 分析器 `TextAnalyze` 输出的是 `DataClass.ChatMessage`。
     - `PerceptionSystem` 的类型标注与部分 import 仍使用 `MessageModel.ChatMessage`。
     - 历史/摘要相关模块也有混用痕迹。
   - 结果：运行时通常还能跑，但会导致类型提示失真、接口对不上、后续重构更难。
   - 建议：定一个“唯一真源”的数据模型（推荐 DataClass 目录），逐步替换旧的 `MessageModel.py`。

## P2（安全性/可维护性问题，建议尽早处理）

1. **API Key 明文硬编码在代码中**
   - ✅ 已修复：
     - [main.py](../main.py) 与 [LLM/QwenFormated.py](../LLM/QwenFormated.py) 已改为从环境变量读取 `OPENAI_API_KEY`。
     - `.env` 已加入 `.gitignore`，适合本地开发。
   - 建议：在 README 补充 `.env` 示例与字段说明（例如 `OPENAI_API_KEY=...`）。
2. **EventBus/PostTurnProcessor 仍是骨架，未形成真实“事件管线”**
    - ✅ 已修复：
       - [EventBus.py](../EventBus.py) 已实现异步队列分发（无事件循环时回退同步派发）。
       - [PostTurnProcessor.py](../PostTurnProcessor.py) 已订阅 `assistant_response_generated`，并触发摘要/状态更新。
    - 仍建议补齐：
       - 增加 `user_input_received` 事件（用于把“分析/写库/状态更新”更明确地拆成管线阶段）。
       - 明确回合后任务的错误隔离与重试策略（避免一个 handler 抛错拖垮整条链路）。

3. **AnalyzeResult 仍未进入 prompt（只落库/挂在 message 上）**
    - 现状：`PerceptionSystem` 会生成并合并 `AnalyzeResult`，并随 `ChatMessage` 落库；但 [ContextAssembler/DefaultGlobalContextAssembler.py](../ContextAssembler/DefaultGlobalContextAssembler.py) 尚未将其转为可控的“摘要信号”注入 prompt。
    - 结果：分析能力无法真正影响主模型回复质量。
    - 建议：把 `AnalyzeResult` 做成轻量 prompt 片段（例如：is_question、entities、keywords、emotion_cues），避免 raw 全量注入。

## 建议的收敛顺序（最小可跑通主链路）

1. ✅ 输入协议已统一（main → Alice → PerceptionSystem）
2. ✅ 在 `Alice.respond()` 中接入 `DefaultGlobalContextAssembler.build_messages()`
3. ✅ 确认 `DefaultChatStateSystem` 实例化与注入（确保 `assemble()` 真正可用）
4. ✅ 修复 `summarize_dialogue` 的字段命名不匹配
5. ✅ 已修复：`python-dotenv` 依赖已补齐（或移除 dotenv）。
6. 统一 LLMManagement 的 `model_map/llm_map` 以及 Qwen 输出格式策略
