# mk1 当前代码需要收尾的集成问题清单

本文档聚焦“能跑通主链路 + 各模块真实接线”的工程收尾问题，按优先级从高到低排列。

## P0（会直接导致主流程不可用 / 产出为空）

1. **输入协议不一致（main → Alice → PerceptionSystem）**
   - 现状：`PerceptionSystem.analyze()` 期望 `{"text": "..."}` 这种媒体类型字典；但 [main.py](../main.py) 目前传的是 `{"media_type": "text", "content": "..."}`。
   - 结果：PerceptionSystem 找不到 `text` analyzer → 返回空；`Alice.process_input()` fallback 又找不到 `text` 字段 → 直接返回 system 错误提示消息。
   - 建议：统一 input schema（推荐 `{"text": user_input}`），或者让 PerceptionSystem 兼容 `media_type/content` 格式。

2. **`Alice.respond()` 尚未把上下文组装器接入**
   - 现状：[Alice.py](../Alice.py) 中 `messages = []  # global context assember`，随后直接把空 messages 发给 client。
   - 结果：LLM 侧要么报错，要么输出不可控（取决于 client 实现）。
   - 建议：在 `Alice` 初始化时创建 `DefaultGlobalContextAssembler`，并在 `respond()` 中使用 `assembler.build_messages()`。

3. **`ContextAssembler/DefaultGlobalContextAssembler` 依赖的方法当前不存在**
   - 现状：它调用 `memory_storage.assemble()` 与 `chat_state_system.assemble()`。
   - 但：
     - [MemorySystem/MemoryStore/MemoryStorage.py](../MemorySystem/MemoryStore/MemoryStorage.py) 没有 `assemble()`。
     - [ChatStateSystem/ChatStateSystem.py](../ChatStateSystem/ChatStateSystem.py) 也没有 `assemble()`（只有 `getChatState()` 等）。
   - 结果：一旦真正接线，会在运行期 `AttributeError`。
   - 建议：
     - 明确“谁负责 assemble”：建议 `MemorySystem` / `ChatStateSystem` 提供 `assemble()`（返回 prompt 片段字符串），或者把组装逻辑都放进 Assembler（ContextAssembler 只拼 messages）。

## P1（逻辑已写但会静默失效 / 质量显著下降）

4. **摘要生成 prompt 的字段命名仍不一致（summarize_dialogue）**
   - 现状：[SystemPrompt.py](../SystemPrompt.py) 中 `summarize_dialogue` 模板使用 `{summary_text}` / `{dialogues_text}`。
   - 但 [MemorySystem/MemoryStore/DialogueStorage.py](../MemorySystem/MemoryStore/DialogueStorage.py) 调用 `LLMManagement.generate(..., summary=summary_text, dialogues_text=dialogues_text)`，参数名 `summary` 不匹配 required_fields。
   - 结果：`LLMManagement.render_prompt()` 会认为缺字段，返回空 prompt → `failuredResponse()` → 摘要永远生成不了（且可能只是日志 warning）。
   - 建议：把调用参数改为 `summary_text=...`。

5. **LLMManagement 的模型映射与实现映射不一致（qwen-plus）**
   - 现状：[LLM/LLMManagement.py](../LLM/LLMManagement.py) 的 `model_map` 有 `generate_response: qwen-plus`，但 `llm_map` 没有 `qwen-plus` 这个 key。
   - 结果：一旦走 `generate_response` 路径会拿不到 llm 实现。
   - 建议：要么把 `llm_map` 增加 `"qwen-plus": QwenFormated()`，要么把 `model_map` 改为指向已有 key（并统一命名）。

6. **QwenFormated 强制 JSON 输出，不一定适用于“生成自然语言回复”**
   - 现状：[LLM/QwenFormated.py](../LLM/QwenFormated.py) 固定 `response_format={"type": "json_object"}`。
   - 风险：如果用于 chat 回复生成，模型会被迫输出 JSON，而不是自然语言。
   - 建议：把“结构化决策类 prompt”和“自然语言回复生成”分开：决策类保持 JSON；回复生成不要强制 JSON。

7. **数据模型混用（MessageModel vs DataClass）**
   - 现状：
     - 分析器 `TextAnalyze` 输出的是 `DataClass.ChatMessage`。
     - `PerceptionSystem` 的类型标注与部分 import 仍使用 `MessageModel.ChatMessage`。
     - 历史/摘要相关模块也有混用痕迹。
   - 结果：运行时通常还能跑，但会导致类型提示失真、接口对不上、后续重构更难。
   - 建议：定一个“唯一真源”的数据模型（推荐 DataClass 目录），逐步替换旧的 `MessageModel.py`。

## P2（安全性/可维护性问题，建议尽早处理）

8. **API Key 明文硬编码在代码中**
   - 现状：`main.py`、`LLM/QwenFormated.py` 等存在明文 key。
   - 风险：泄露后无法控制成本与权限；也不利于开源/共享。
   - 建议：改为环境变量读取（例如 `DASHSCOPE_API_KEY`），并在 README 写明配置方式。

9. **EventBus/PostTurnProcessor 仍是骨架，未形成真实“事件管线”**
   - 现状：[EventBus.py](../EventBus.py) 的 `subscribe/publish` 仍是 `pass`，[PostTurnProcessor.py](../PostTurnProcessor.py) 也未实现。
   - 建议：如果目标是“输入/状态/摘要/工具调用”管线化，先实现最小可用：
     - `publish()` 入队
     - consumer loop 分发到 handlers
     - 先接 `USER_INPUT_RECEIVED` → 更新 chat_state / 写历史

## 建议的收敛顺序（最小可跑通主链路）

1. 统一 input schema（main → Alice → PerceptionSystem）
2. 在 `Alice.respond()` 中接入 `DefaultGlobalContextAssembler.build_messages()`
3. 补齐/调整 `assemble()` 的归属（Memory/ChatState 的 prompt 片段从哪里来）
4. 修复 `summarize_dialogue` 的字段命名不匹配
5. 统一 LLMManagement 的 `model_map/llm_map` 以及 Qwen 输出格式策略
