# 阶段进展（截至 2026-01-13）

本文档记录 2026-01-13 这轮“大幅更新”后，项目结构与主链路的真实状态，并对齐 docs/TODO.md、docs/项目总结.md、docs/集成收尾问题清单.md。

## 本轮更新摘要

- 完成 `src/` 目录化重构：核心代码已迁移到 `src/` 下，`pyproject.toml` 使用 `tool.setuptools.packages.find(where=["src"])`。
- 引入 Prompt 构建系统：新增 `PromptBuilder`/`PromptNode`，用于可组合地构建 system prompt（支持 include/extend/tag/container/priority）。
- AnalyzeResult 已进入 prompt：`DefaultGlobalContextAssembler` 会把近期多轮 `AnalyzeResult` 转成 `<ANALYZE>` 块注入 system prompt。
- LLM 调用链更清晰：`LLMManagement` 同时提供
  - `generate()`：结构化 JSON 输出（例如裁判/摘要/分析）
  - `chat()`：自然语言对话回复（Ollama chat）
- 新增 tests：增加了针对 PromptBuilder/normalize/LTP/AnalyzeResult merge 的基础测试文件，便于后续重构回归。

## 当前主链路（简述）

1. `main.py` 读取环境变量并启动交互循环
2. `Alice.respond()` 调用 `PerceptionSystem.analyze()` 并发分析文本（OllamaAnalyze + LtpAnalyze）
3. 写入 SQLite（ChatMessage + 可选 AnalyzeResult）
4. `DefaultGlobalContextAssembler.build_messages(user_input)`：构建 system prompt（Memory + ChatState + Analyze + ResponseProtocol）并拼接 recent history
5. `LLMManagement.chat(messages, "qw8")`：生成 assistant 回复
6. 写入 SQLite，并发布 `assistant_response_generated` 事件触发回合后处理（摘要/状态更新）

## 仍待处理/风险点（建议优先）

1. `src/` layout 下 import 风格一致性：避免出现“uv run 直接跑脚本 ok，但安装为包后不一致”的问题。
2. `<ANALYZE>` 注入的长度与筛选策略：建议只保留最近 N 轮、只喂关键字段（keywords/entities/is_question/emotion_cues 等）。
3. 多模态端到端：目前 `ChatMessage` 已预留 voice/image/video，但缺少对应分析器与主链路接线/存储协议。
