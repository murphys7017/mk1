# mk1（Alice）智能体系统项目总结

## 项目定位

mk1 是一个具备“感知 → 记忆 → 推理 →（行动，规划中）→ 记忆更新”认知闭环的智能体原型。
当前以 Alice 为顶层智能体角色，支持多轮对话、对话摘要、对话状态更新，并在向“可插拔 LLM / 可插拔上下文组装 / 事件驱动”方向重构。

## 当前主流程（main/Alice）

1. CLI 接收用户输入（`main.py`）
2. `Alice.respond()` 调用 `PerceptionSystem.analyze()` 并发分析输入（Ollama 文本分析 + LTP 结构化分析）
3. 生成 `ChatMessage`（text 为主，已预留 voice/image/video 字段，并可附带 `AnalyzeResult`）
4. `QuerySystem` 构建 `QuerySchema` 并挂载到 user `ChatMessage`（用于后续检索/路由决策）
5. 将 user 消息写入 SQLite 历史记录（包含可选的 `AnalyzeResult` 持久化；QuerySchema 目前主要运行时使用）
6. `DefaultGlobalContextAssembler.build_messages()` 组装 system prompt（Memory + ChatState + Analyze + ResponseProtocol）+ recent history
7. 调用 `LLMManagement.chat()` 生成回复（当前默认走本地 Ollama chat，例如 `qw8`）
8. 将 assistant 回复写入 SQLite 历史记录
9. 发布 `assistant_response_generated` 事件，触发回合后处理（摘要/状态更新 + PostTreatmentSystem 等）

## 模块分层与职责

- 入口与顶层：`main.py`、`src/Alice.py`
- 感知系统：`src/PerceptionSystem/`（OllamaAnalyze + LTP Analyze 并发合并）
- QuerySystem：`src/QuerySystem/`（生成 QuerySchema：signal density、intent、检索模式等）
- 记忆系统：`src/MemorySystem/`（策略、存储、组装、摘要）
- 对话状态：`src/ChatStateSystem/`（状态判定与输出）
- 上下文组装：`src/ContextAssembler/`（PromptBuilder 拼接记忆/状态/分析/协议 + recent history）
- LLM 管理：`src/LLM/`（结构化生成：OllamaFormated；对话：OllamaChat；统一入口：LLMManagement）
- 历史持久化：`src/RawChatHistory/`（SQLite / 文件版备用）
- 数据模型：`src/DataClass/`（ChatMessage、AnalyzeResult、DialogueMessage、ChatState 等）
- 事件驱动：`src/EventBus.py` / `src/PostTurnProcessor.py`
- 回合后处理：`src/PostTreatmentSystem/`（PostHandleSystem + handlers；可扩展 Live2D 等外部输出）
- Prompt 构建：`src/tools/PromptBuilder.py`（用于可组合、可插拔的 system prompt 构建）
- 传输层：`src/Transport/`（WebSocket server 等实验性接口）
- 测试：`tests/`（针对 prompt builder、normalize、ltp、AnalyzeResult 合并等）

## 当前集成状态（要点）

- ✅ `src/` 目录化重构完成：核心代码统一在 `src/` 下，便于包管理与测试
- ✅ `DefaultGlobalContextAssembler` 已接入 `Alice.respond()`，主链路可用（system prompt + recent history）
- ✅ `AnalyzeResult` 已注入 system prompt（以“轻量信号/结构化摘要”形式，而非 raw 全量）
- ✅ `LLMManagement` 已区分“结构化生成（JSON）”与“对话回复（自然语言）”两条调用链
- ✅ `EventBus` 已实现队列分发，`PostTurnProcessor` 已订阅 assistant 回复事件并触发摘要/状态更新
- ✅ QuerySystem 已接入主链路：对 user 消息生成 QuerySchema（用于后续检索/路由闭环）
- ✅ PostTreatmentSystem 已接入回合后流程：在事件触发后异步调度 handler 管线（含 Live2D 相关能力）
- ✅ `RawChatHistory` 已统一走 SQLite（并支持 `AnalyzeResult` 1:1 关联持久化）
- ✅ 数据模型已收敛到 `src/DataClass/`（`MessageModel.py` 已移除）

## 技术栈与依赖

- Python >= 3.11
- 依赖：loguru、sqlalchemy、python-dotenv、pytest/pytest-asyncio
- 本地推理：Ollama（例如 `qwen3:1.7b`、`qwen3:4b`、`qwen3:8b`）
- 存储：SQLite（`chat_history.db`）

## 运行方式（简要）

```bash
uv sync
uv run .\main.py
```

## 近期计划（摘自 docs/TODO.md）

- 输入与输出解耦，支持多次输入后再由 AI 输出
- 设计并接入管线化或事件化处理流程
- 增加 TTS / STT，实现语音交互
- 设计长期记忆模块，使 AI 稳定记住用户基础信息

## 补充计划

- （已完成）将 `AnalyzeResult` 以“摘要/信号”的形式注入 system prompt（避免把 raw 全量塞进 prompt）
- （已完成）统一 `LLMManagement` 的模型命名与实现映射，明确“结构化输出（JSON）”与“自然语言回复”两条路径
- 下一步：补齐 image/audio/video 的分析器与端到端链路（目前仅预留字段/协议）

## 参考文档

- `README.md`
- `docs/gpt-整体流程.md`
- `docs/集成收尾问题清单.md`
- `docs/TODO.md`
