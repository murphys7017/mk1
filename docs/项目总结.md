# mk1（Alice）智能体系统项目总结（更新版）

## 项目定位

mk1 是一个具备“感知 → 记忆 → 推理 → 行动（规划中）→ 记忆更新”认知闭环的智能体原型；当前以 **Alice（爱丽丝）** 为顶层智能体角色，支持多轮对话、对话摘要、对话状态更新，并开始向“可插拔 LLM / 可插拔上下文组装 / 事件驱动”方向重构。

## 当前整体处理流程（以 main/Alice 为准）

1. 终端输入文本（[main.py](../main.py)）
2. 调用 `Alice.respond(user_inputs)`（异步）
3. `PerceptionSystem.analyze()` 并发执行分析器（目前主要是 text）→ 得到 `ChatMessage` 列表
4. 选择聚合输入（当前默认取最后一个）
5. （建设中）构建全局上下文 messages
  - `ContextAssembler/DefaultGlobalContextAssembler` 已能把“记忆块（memory_storage）+ 对话状态块（chat_state_system）”合并为 system prompt，并拼接最近原始对话
  - 但 `Alice.respond()` 里目前仍未真正调用该 assembler（messages 仍是占位空列表）
6. 调用云端 LLM 客户端生成回复（当前仍由 `Agent/QwenClient.py` 负责）
7. 将 assistant 回复写入历史（SQLite `chat_history.db`）
8. 后处理，发布`ASSISTANT_RESPONSE_GENERATED` 等事件通知记忆系统等进行后处理（开发中）

> 注：你的“记忆系统 assemble / 对话摘要 / 对话状态”相关代码已经抽象得更清晰，但目前还没有在 `Alice.respond()` 中完整串起来（属于正在集成阶段）。

## 模块分层与职责

### 1) 入口与顶层智能体

- [main.py](../main.py)
  - 交互式 CLI 入口
  - 现在采用 `asyncio.run(main())` 驱动异步 `Alice.respond()`
- [Alice.py](../Alice.py)
  - 顶层编排器：初始化历史管理、LLM 管理、感知系统、记忆系统
  - `process_input()`：调用感知系统并做 fallback（分析失败则回退为纯文本 user message）
  - `respond()`：生成回复并落库（当前“上下文组装 messages”仍是 TODO）

### 2) DataClass：核心数据结构（新）

新增 [DataClass/](../DataClass/) 作为“领域模型层”，把关键结构独立出来：

- [DataClass/ChatMessage.py](../DataClass/ChatMessage.py)：对话消息（role/content/time/media/extra/chat_turn_id）
- [DataClass/DialogueMessage.py](../DataClass/DialogueMessage.py)：阶段摘要（dialogue_id/start/end/summary/is_completed）
- [DataClass/ChatState.py](../DataClass/ChatState.py)：对话状态（含 `updated_at`）
- [DataClass/PromptTemplate.py](../DataClass/PromptTemplate.py)：提示词模板 + required_fields + 输出 schema
- [DataClass/EventType.py](../DataClass/EventType.py) 与 [DataClass/ChatEvent.py](../DataClass/ChatEvent.py)：事件类型与事件载体（为事件驱动预埋）
- [DataClass/TagType.py](../DataClass/TagType.py)：上下文标签枚举（IDENTITY/MEMORY 等）

> 现状提醒：工程里同时还保留了旧的 [MessageModel.py](../MessageModel.py)，部分模块仍在混用 `MessageModel.ChatMessage` 与 `DataClass.ChatMessage`（属于重构过渡期现象）。

### 3) LLM：统一模型调用与提示词编排（新）

- [LLM/LLMAbstract.py](../LLM/LLMAbstract.py)：LLM 接口（`generate()`/`failuredResponse()`）
- [LLM/Ollama.py](../LLM/Ollama.py)：本地 Ollama 调用，抽取 JSON 输出
- [LLM/QwenFormated.py](../LLM/QwenFormated.py)：通义千问兼容 OpenAI 接口调用（JSON 格式返回）
- [LLM/LLMManagement.py](../LLM/LLMManagement.py)：统一入口
  - `model_map`：把 prompt_name → 模型名（如 `text_analysis`→`qwen3:1.7b`，`generate_response`→`qwen-plus`）
  - `system_prompt`：通过 `SystemPrompt.getPrompt()` 获取模板
  - `render_prompt()`：用 required_fields 校验并渲染 prompt
  - `generate()`：选择模型实现并执行

### 4) SystemPrompt：模板注册中心（升级）

- [SystemPrompt.py](../SystemPrompt.py)
  - 从“静态函数集合”升级为“PromptTemplate 注册中心”
  - `load_template()` 将各 prompt_name 注册到 `prompt_map`
  - `getPrompt(prompt_name)` 返回对应 PromptTemplate

> 本次更新点：`SystemPrompt.__init__()` 里已自动调用 `load_template()`，避免了此前“忘记加载导致 prompt_map 为空”的问题。

> 现状提醒：`SystemPrompt.load_template()` 需要在运行时被调用一次，否则 `prompt_map` 为空；同时部分模板的 `required_fields` 与实际 format 占位符命名目前存在不一致风险（会导致 `render_prompt()` 直接返回空字符串，从而走失败返回）。这属于“重构集成待收尾”的部分。

### 5) 感知系统 PerceptionSystem（异步并发化）

- [PerceptionSystem/Analyzeabstract.py](../PerceptionSystem/Analyzeabstract.py)：分析器抽象基类
- [PerceptionSystem/PerceptionSystem.py](../PerceptionSystem/PerceptionSystem.py)
  - 将输入从单条变为 `dict[str, Any]`（例如 `{ "text": "hello" }`）
  - 使用 `asyncio` + `run_in_executor` 并发运行多个 analyzer，并设置整体 `timeout`
  - 当前注册：`"text" -> TextAnalyze`

### 6) 记忆系统 MemorySystem（重构中，功能仍以“身份 + 摘要”主）

- [MemorySystem/MemorySystem.py](../MemorySystem/MemorySystem.py)
  - 现在主要提供 `assemble()`，返回用于 system prompt 的“结构化记忆块”文本
- [MemorySystem/MemoryAssembler.py](../MemorySystem/MemoryAssembler.py)
  - 负责拼装：Identity / World / Long / Knowledge / Mid（摘要）等标签块
  - 当前“chat_state / response_guidelines / raw_history 拼接”相关代码暂时注释/未接入
- [MemorySystem/MemoryPolicy.py](../MemorySystem/MemoryPolicy.py)
  - 通过 `LLMManagement.generate()` 完成“是否摘要 / 话题延续分割”决策
- [MemorySystem/MemoryStore/DialogueStorage.py](../MemorySystem/MemoryStore/DialogueStorage.py)
  - raw_buffer 缓冲
  - 达到阈值后：裁决是否摘要 → 需要则生成摘要（qwen3:4b）并写入历史
- [MemorySystem/MemoryStore/IdentitiyMemory.py](../MemorySystem/MemoryStore/IdentitiyMemory.py)
  - 身份核心设定 + `Alice_personality.txt`

### 7) ChatStateSystem：对话状态更新（新）

- [ChatStateSystem/ChatStateSystem.py](../ChatStateSystem/ChatStateSystem.py)
  -（类名仍为 `ChatStateStorage`）
  - 基于最近 N 轮对话调用 `LLMManagement` 的 `judge_chat_state` prompt
  - 维护 `ChatState.updated_at`，用于控制更新频率

### 8) ContextAssembler：上下文组装（新，正在接入）

- [ContextAssembler/GlobalContextAssembler.py](../ContextAssembler/GlobalContextAssembler.py)：上下文组装接口
- [ContextAssembler/DefaultGlobalContextAssembler.py](../ContextAssembler/DefaultGlobalContextAssembler.py)
  - 将 `memory_storage.assemble()`（记忆块）+ `chat_state_system.assemble()`（状态块）合并为 system prompt，再拼接最近原始对话 history 组成 messages
  - 目标是作为 `Alice.respond()` 中 messages 的来源（目前尚未完全接线）

### 9) 原始历史与持久化

- [RawChatHistory/RawChatHistory.py](../RawChatHistory/RawChatHistory.py)：历史接口封装（message/dialogue 的增删查）
- [RawChatHistory/SqlitManagementSystem.py](../RawChatHistory/SqlitManagementSystem.py)：SQLite + SQLAlchemy ORM
- [RawChatHistory/RawChatHistoryFile.py](../RawChatHistory/RawChatHistoryFile.py)：文件版历史（备用）

### 10) EventBus：事件驱动骨架（新，未实现）

- [EventBus.py](../EventBus.py)
  - 提供订阅/发布接口与异步队列雏形，但 `subscribe()` / `publish()` 目前仍是 `pass`
  - 结合 `DataClass/EventType.py`，未来可把“输入接收/状态更新/响应生成”等流程解耦为事件流

### 11) PostTurnProcessor：事件处理器骨架（新，未实现）

- [PostTurnProcessor.py](../PostTurnProcessor.py)
  - 用于在 `EventBus` 中注册“回合结束后的处理函数”（例如：更新状态、写摘要、触发工具等）
  - 当前仅有空壳，尚未接入

## 技术栈

- Python >= 3.10（见 [pyproject.toml](../pyproject.toml)）
- 日志：loguru
- 本地推理：Ollama HTTP API
- 云端推理：DashScope 兼容 OpenAI API（qwen-plus）
- 存储：SQLite + SQLAlchemy（默认库文件：`chat_history.db`）

## 当前开发计划（来自 docs/TODO.md）

- 将输入与输出分开，支持“多次输入 → AI 视情况输出”（管线化/事件化方向）
- 添加 TTS/STT（语音对话）
- 设计长期记忆模块（让 AI 稳定记住用户基本信息）

